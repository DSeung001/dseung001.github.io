#!/usr/bin/env python3
"""
ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì— ëŒ€í•œ AI ë¦¬ë·°ë¥¼ ìƒì„±í•˜ê³  Giscus Discussionì— ì½”ë©˜íŠ¸ë¡œ ì¶”ê°€
- í•œ ê¸€ë‹¹ ë¦¬ë·° í•˜ë‚˜ë§Œ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
- ì „ì²´ ê¸€ ë‚´ìš©ì— ëŒ€í•œ ë¦¬ë·°
"""
import os
import re
import sys
import subprocess
from pathlib import Path
import google.generativeai as genai
import requests
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
GITHUB_REPO = 'DSeung001/dseung001.github.io'
TARGET_FILE = os.getenv('TARGET_FILE', '')  # íŠ¹ì • íŒŒì¼ ì§€ì • (ì„ íƒì )

# GitHub API ì„¤ì •
GITHUB_API_BASE = 'https://api.github.com'
GITHUB_HEADERS = {
    'Authorization': f'token {GITHUB_TOKEN}',
    'Accept': 'application/vnd.github.v3+json',
    'X-GitHub-Api-Version': '2022-11-28'
}

# Gemini API ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-pro')

# ë¦¬ë·° í”„ë¡¬í”„íŠ¸
REVIEW_PROMPT = """ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ê¸€ì„ ì „ë¬¸ì ìœ¼ë¡œ ë¦¬ë·°í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ë¸”ë¡œê·¸ ê¸€ì„ ì½ê³  ì•„ë˜ í•­ëª©ë“¤ì„ í¬í•¨í•œ ìƒì„¸í•œ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **ê¸€ì˜ ê°•ì **: ê¸€ì˜ ì˜ëœ ì , ëª…í™•í•˜ê²Œ ì„¤ëª…ëœ ë¶€ë¶„
2. **ê°œì„  ì œì•ˆ**: ë” ëª…í™•í•˜ê²Œ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„, ì¶”ê°€í•˜ë©´ ì¢‹ì„ ë‚´ìš©
3. **ê¸°ìˆ ì  ì •í™•ì„±**: ê¸°ìˆ ì  ë‚´ìš©ì˜ ì •í™•ì„±ê³¼ ê°œì„ ì 
4. **ê°€ë…ì„±**: êµ¬ì¡°, ë¬¸ì¥, ì˜ˆì œ ì½”ë“œì˜ ê°€ë…ì„±
5. **ê³ ì°°**: ì´ ê¸€ì— ëŒ€í•œ ê³ ì°°
6. **ì¢…í•© í‰ê°€**: ì „ì²´ì ì¸ í‰ê°€ì™€ ì¶”ì²œ ì‚¬í•­

ë¦¬ë·°ëŠ” ê±´ì„¤ì ì´ê³  ì¹œì ˆí•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë©°, êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì œì•ˆí•´ì£¼ì„¸ìš”.
ë¦¬ë·°ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

def get_target_files():
    """ë¦¬ë·°í•  íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    # 1. TARGET_FILE í™˜ê²½ ë³€ìˆ˜ë¡œ íŠ¹ì • íŒŒì¼ ì§€ì •
    if TARGET_FILE:
        if os.path.exists(TARGET_FILE):
            return [TARGET_FILE]
        else:
            print(f"âš ï¸  ì§€ì •ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TARGET_FILE}")
            return []
    
    # 2. workflow_dispatchì˜ inputsì—ì„œ íŒŒì¼ ì§€ì •
    event_path = os.getenv('GITHUB_EVENT_PATH')
    if event_path and os.path.exists(event_path):
        try:
            import json
            with open(event_path, 'r') as f:
                event = json.load(f)
                inputs = event.get('inputs', {})
                target = inputs.get('file_path', '')
                if target and os.path.exists(target):
                    return [target]
        except:
            pass
    
    # 3. Push ì´ë²¤íŠ¸ì˜ ê²½ìš° ë³€ê²½ëœ íŒŒì¼ë§Œ
    if os.getenv('GITHUB_EVENT_NAME') == 'push':
        try:
            before = os.getenv('GITHUB_SHA') + '~1'
            after = os.getenv('GITHUB_SHA')
            
            result = subprocess.run(
                ['git', 'diff', '--name-only', '--diff-filter=AM', before, after],
                capture_output=True,
                text=True,
                check=True
            )
            files = [
                f.strip() for f in result.stdout.split('\n')
                if f.strip().endswith('.md') and 'content/posts' in f
            ]
            return files
        except Exception as e:
            print(f"Error getting changed files: {e}")
            return []
    
    # 4. ëª¨ë“  í¬ìŠ¤íŠ¸ íŒŒì¼ (workflow_dispatchì—ì„œ ì „ì²´ ë¦¬ë·° ì˜µì…˜)
    posts_dir = Path('content/posts')
    if posts_dir.exists():
        md_files = list(posts_dir.rglob('*.md'))
        return [str(f) for f in md_files]
    
    return []

def read_markdown_file(filepath):
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"Error reading {filepath}: {e}")
        return None

def extract_front_matter(content):
    """Front matterì—ì„œ ì œëª©ê³¼ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    front_matter_match = re.match(r'^---\n(.*?)\n---\n(.*)$', content, re.DOTALL)
    if front_matter_match:
        front_matter = front_matter_match.group(1)
        body = front_matter_match.group(2)
        
        title_match = re.search(r'^title:\s*["\']?(.*?)["\']?$', front_matter, re.MULTILINE)
        title = title_match.group(1) if title_match else "Unknown"
        
        return title, body
    return None, content

def filepath_to_permalink(filepath):
    """
    íŒŒì¼ ê²½ë¡œë¥¼ Hugo permalinkë¡œ ë³€í™˜
    config.toml: posts = "/posts/:year/:month/:day/:contentbasename/"
    """
    path = Path(filepath)
    parts = path.parts
    
    if 'content' in parts and 'posts' in parts:
        posts_idx = parts.index('posts')
        post_parts = parts[posts_idx + 1:]
    else:
        return None
    
    if len(post_parts) < 4:
        return None
    
    year = post_parts[0]
    month = post_parts[1]
    day = post_parts[2]
    
    if len(post_parts) > 4:
        basename = post_parts[3]
    else:
        basename = post_parts[3].replace('.md', '').replace('index', '')
    
    basename = re.sub(r'[^\w\s-]', '', basename).strip()
    basename = re.sub(r'[-\s]+', '-', basename).lower()
    
    permalink = f"/posts/{year}/{month}/{day}/{basename}/"
    return permalink

def find_discussion_by_permalink(permalink):
    """permalinkë¡œ Discussion ì°¾ê¸°"""
    url = f"{GITHUB_API_BASE}/repos/{GITHUB_REPO}/discussions"
    params = {'per_page': 100, 'state': 'all'}
    
    page = 1
    while True:
        params['page'] = page
        response = requests.get(url, headers=GITHUB_HEADERS, params=params)
        
        if response.status_code != 200:
            print(f"Error fetching discussions: {response.status_code}")
            return None
        
        discussions = response.json()
        if not discussions:
            break
        
        for discussion in discussions:
            body = discussion.get('body', '').lower()
            title = discussion.get('title', '').lower()
            permalink_lower = permalink.lower()
            
            if permalink_lower in body or permalink_lower in title:
                return discussion['number']
            
            discussion_url = discussion.get('html_url', '')
            if permalink_lower.replace('/', '') in discussion_url.lower():
                return discussion['number']
        
        page += 1
        if len(discussions) < 100:
            break
    
    return None

def has_existing_ai_review(discussion_number):
    """Discussionì— ì´ë¯¸ AI ë¦¬ë·° ì½”ë©˜íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸"""
    url = f"{GITHUB_API_BASE}/repos/{GITHUB_REPO}/discussions/{discussion_number}/comments"
    params = {'per_page': 100}
    
    page = 1
    while True:
        params['page'] = page
        response = requests.get(url, headers=GITHUB_HEADERS, params=params)
        
        if response.status_code != 200:
            return False
        
        comments = response.json()
        if not comments:
            break
        
        for comment in comments:
            body = comment.get('body', '')
            # AI ë¦¬ë·° ë§ˆì»¤ í™•ì¸
            if 'ğŸ¤– AI ë¦¬ë·°:' in body or 'Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ìƒì„±' in body:
                return True
        
        page += 1
        if len(comments) < 100:
            break
    
    return False

def generate_review(content):
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° ìƒì„± (ì „ì²´ ë‚´ìš©)"""
    try:
        # ì „ì²´ ë‚´ìš© ì‚¬ìš© (ë³€ê²½ ë‚´ì—­ì´ ì•„ë‹Œ)
        # Gemini í† í° ì œí•œ ê³ ë ¤í•˜ì—¬ ìµœëŒ€ 30000ìê¹Œì§€
        content_for_review = content[:30000] if len(content) > 30000 else content
        
        if len(content) > 30000:
            print(f"âš ï¸  ë‚´ìš©ì´ ê¸¸ì–´ì„œ ì²˜ìŒ 30000ìë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        prompt = REVIEW_PROMPT + content_for_review
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"Error generating review: {e}")
        return None

def create_discussion_comment(discussion_number, review_text, post_title):
    """Discussionì— ë¦¬ë·° ì½”ë©˜íŠ¸ ì¶”ê°€"""
    url = f"{GITHUB_API_BASE}/repos/{GITHUB_REPO}/discussions/{discussion_number}/comments"
    
    comment_body = f"""## ğŸ¤– AI ë¦¬ë·°: {post_title}

{review_text}

---
*ì´ ë¦¬ë·°ëŠ” Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*  
*ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S KST')}*
"""
    
    data = {'body': comment_body}
    
    response = requests.post(url, headers=GITHUB_HEADERS, json=data)
    
    if response.status_code == 201:
        comment_url = response.json().get('html_url', '')
        print(f"âœ… ë¦¬ë·° ì½”ë©˜íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"   ì½”ë©˜íŠ¸ URL: {comment_url}")
        return True
    else:
        print(f"âŒ ì½”ë©˜íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {response.status_code}")
        print(f"Response: {response.text}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    if not GITHUB_TOKEN:
        print("âŒ GITHUB_TOKEN í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # ëŒ€ìƒ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    target_files = get_target_files()
    
    if not target_files:
        print("ğŸ“ ë¦¬ë·°í•  í¬ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ë¦¬ë·°í•  íŒŒì¼: {len(target_files)}ê°œ\n")
    
    success_count = 0
    skip_count = 0
    error_count = 0
    
    for filepath in target_files:
        print(f"{'='*60}")
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {filepath}")
        
        # íŒŒì¼ ì½ê¸°
        content = read_markdown_file(filepath)
        if not content:
            print("âš ï¸  íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\n")
            error_count += 1
            continue
        
        # Front matterì—ì„œ ì œëª© ì¶”ì¶œ
        title, body = extract_front_matter(content)
        print(f"ğŸ“Œ ì œëª©: {title}")
        
        # Permalink ê³„ì‚°
        permalink = filepath_to_permalink(filepath)
        if not permalink:
            print(f"âš ï¸  Permalinkë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\n")
            error_count += 1
            continue
        print(f"ğŸ”— Permalink: {permalink}")
        
        # Discussion ì°¾ê¸°
        print(f"ğŸ” Discussion ì°¾ëŠ” ì¤‘...")
        discussion_number = find_discussion_by_permalink(permalink)
        
        if not discussion_number:
            print(f"âš ï¸  Discussionì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   Permalink: {permalink}")
            print(f"   í•´ë‹¹ í¬ìŠ¤íŠ¸ì˜ ëŒ“ê¸€ ì„¹ì…˜ì„ í•œ ë²ˆ ë°©ë¬¸í•˜ë©´ Discussionì´ ìƒì„±ë©ë‹ˆë‹¤.\n")
            error_count += 1
            continue
        
        print(f"âœ… Discussion #{discussion_number} ì°¾ìŒ")
        
        # ì´ë¯¸ ë¦¬ë·°ê°€ ìˆëŠ”ì§€ í™•ì¸
        print(f"ğŸ” ê¸°ì¡´ ë¦¬ë·° í™•ì¸ ì¤‘...")
        if has_existing_ai_review(discussion_number):
            print(f"â­ï¸  ì´ë¯¸ AI ë¦¬ë·°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\n")
            skip_count += 1
            continue
        
        print(f"âœ… ìƒˆë¡œìš´ ë¦¬ë·° ìƒì„± ê°€ëŠ¥")
        
        # ë¦¬ë·° ìƒì„± (ì „ì²´ ë‚´ìš©)
        print("ğŸ¤– AI ë¦¬ë·° ìƒì„± ì¤‘...")
        review = generate_review(body)
        
        if not review:
            print("âŒ ë¦¬ë·° ìƒì„± ì‹¤íŒ¨\n")
            error_count += 1
            continue
        
        print("âœ… ë¦¬ë·° ìƒì„± ì™„ë£Œ")
        
        # ì½”ë©˜íŠ¸ ì¶”ê°€
        print(f"ğŸ’¬ Discussionì— ì½”ë©˜íŠ¸ ì¶”ê°€ ì¤‘...")
        if create_discussion_comment(discussion_number, review, title):
            success_count += 1
        else:
            error_count += 1
        print()
    
    # ê²°ê³¼ ìš”ì•½
    print(f"{'='*60}")
    print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"   â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ë¦¬ë·° ì¡´ì¬): {skip_count}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {error_count}ê°œ")

if __name__ == '__main__':
    main()